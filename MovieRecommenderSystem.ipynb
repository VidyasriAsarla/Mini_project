{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VidyasriAsarla/Mini_project/blob/main/MovieRecommenderSystem.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VCihp32AFjXI"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pmnLNvw6FpOO",
        "outputId": "d17ebd27-55a0-4b89-9279-92e9042412aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-c1ff7f70ed48>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# uploaded = files.upload()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tmdb_5000_movies.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdf2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tmdb_5000_credits.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    676\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    930\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 932\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    933\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1214\u001b[0m             \u001b[0;31m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0;31m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m             self.handles = get_handle(  # type: ignore[call-overload]\n\u001b[0m\u001b[1;32m   1217\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    784\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 786\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    787\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'tmdb_5000_movies.csv'"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "# uploaded = files.upload()\n",
        "df1 = pd.read_csv(\"tmdb_5000_movies.csv\")\n",
        "df2 = pd.read_csv(\"tmdb_5000_credits.csv\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-HSEDpxrWwUf"
      },
      "source": [
        "**Data Preprocessing Starts**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EVMwlfzCMF0y"
      },
      "outputs": [],
      "source": [
        "df1.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QF6yXswyMKgP"
      },
      "outputs": [],
      "source": [
        "df2.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YnMCOLnJFpQ3"
      },
      "outputs": [],
      "source": [
        "df = df1.merge(df2, on = \"title\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kV3qdWJKMZF-"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fjUpX4XGMZHz"
      },
      "outputs": [],
      "source": [
        "df[\"original_language\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U4Uovk0QMZLQ"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LBwavqL2FpUS"
      },
      "outputs": [],
      "source": [
        "# Selecting features\n",
        "features = [\"movie_id\", \"title\", \"overview\", \"genres\", \"keywords\", \"cast\", \"crew\"]\n",
        "\n",
        "df = df[features]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5n2ucEmqPhKK"
      },
      "outputs": [],
      "source": [
        "# Removing rows with nan values\n",
        "df.dropna(inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pgJCEZ0uP62W"
      },
      "outputs": [],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_-RNNFhcPo4p"
      },
      "outputs": [],
      "source": [
        "# Checking for duplicate rows\n",
        "df.duplicated().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "895BqusPQMH9"
      },
      "outputs": [],
      "source": [
        "df.iloc[0].genres"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iE45-SHkQZDj"
      },
      "outputs": [],
      "source": [
        "import ast\n",
        "def convert(obj):\n",
        "  _list = []\n",
        "  # ast.literal_eval converts string into dictionary or object\n",
        "  for val in ast.literal_eval(obj):\n",
        "    _list.append(val[\"name\"])\n",
        "  return _list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iGnkw8xkQ1fI"
      },
      "outputs": [],
      "source": [
        "# Making a list of only genres and not including unwanted data\n",
        "df[\"genres\"] = df[\"genres\"].apply(convert)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vt33RNP2Q1il"
      },
      "outputs": [],
      "source": [
        "# Making a list of only keywords and not including unwanted data\n",
        "df[\"keywords\"] = df[\"keywords\"].apply(convert)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tNCWvSOdRluC"
      },
      "outputs": [],
      "source": [
        "df[\"cast\"][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "thRWxf8BRlwA"
      },
      "outputs": [],
      "source": [
        "# We want only most important actors in the cast\n",
        "def get_top_actors(obj):\n",
        "  _list = []\n",
        "  count = 0\n",
        "  for val in ast.literal_eval(obj):\n",
        "    if count == 3:\n",
        "      break\n",
        "    _list.append(val[\"name\"])\n",
        "    count += 1\n",
        "  return _list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hs2DBShKRlzb"
      },
      "outputs": [],
      "source": [
        "# Making a list of only top 3 actors in the movie\n",
        "df[\"cast\"] = df[\"cast\"].apply(get_top_actors)\n",
        "df[\"cast\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GqgBjRgCSDny"
      },
      "outputs": [],
      "source": [
        "df[\"crew\"][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f0W9Q9oqSDp_"
      },
      "outputs": [],
      "source": [
        "# We want only director from the crew\n",
        "def get_director(obj):\n",
        "  _list = []\n",
        "  count = 0\n",
        "  for val in ast.literal_eval(obj):\n",
        "    if val[\"job\"] == \"Director\":\n",
        "      _list.append(val[\"name\"])\n",
        "      break\n",
        "  return _list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_mLymfOKSDtf"
      },
      "outputs": [],
      "source": [
        "# Making a list of directors only from the crew\n",
        "df[\"directors\"] = df[\"crew\"].apply(get_director)\n",
        "df[\"directors\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "63mpgB-aTiv7"
      },
      "outputs": [],
      "source": [
        "df[\"overview\"][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JwG3FRFITizp"
      },
      "outputs": [],
      "source": [
        "# Converting string into list of overview\n",
        "df[\"overview\"] = df[\"overview\"].apply(lambda x: x.split())\n",
        "df[\"overview\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YrvxjpG0Ti3M"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-jQq4v5HUOY_"
      },
      "outputs": [],
      "source": [
        "# Replacing spaces with empty string in all columns   (This helps model to differentiate between 2 different strings that have same first name)\n",
        "df[\"genres\"] = df[\"genres\"].apply(lambda x : [i.replace(\" \", \"\") for i in x])\n",
        "df[\"keywords\"] = df[\"keywords\"].apply(lambda x : [i.replace(\" \", \"\") for i in x])\n",
        "df[\"cast\"] = df[\"cast\"].apply(lambda x : [i.replace(\" \", \"\") for i in x])\n",
        "df[\"directors\"] = df[\"directors\"].apply(lambda x : [i.replace(\" \", \"\") for i in x])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VJ94OXLjUOat"
      },
      "outputs": [],
      "source": [
        "# Making a new column tags that stores all the data of all the 4 columns\n",
        "df[\"tags\"] = df[\"overview\"] + df[\"keywords\"] + df[\"cast\"] + df[\"directors\"]\n",
        "df[\"tags\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pCEgNGM6UOch"
      },
      "outputs": [],
      "source": [
        "# Creating a new dataframe of just 3 columns after doing so  much preprocessing\n",
        "new_df = df[[\"movie_id\", \"title\", \"tags\"]]\n",
        "new_df[\"tags\"][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0VzKMhC-UOep"
      },
      "outputs": [],
      "source": [
        "# Converting list into string with spaces\n",
        "new_df[\"tags\"] = new_df[\"tags\"].apply(lambda x : \" \".join(x))\n",
        "new_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nEiICb0HUOh6"
      },
      "outputs": [],
      "source": [
        "# Making all the letters in the string to lowercase\n",
        "new_df[\"tags\"] = new_df[\"tags\"].apply(lambda x : x.lower())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smdJ8sWKW-Up"
      },
      "source": [
        "**Using Stemming technique to convert normal words into root words**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yOa4rZOib9C9"
      },
      "outputs": [],
      "source": [
        "# As we can see similar words are considered as different words in the vectorizer, we will use stemming to remove this ambiguity\n",
        "# stemming converts all the words to its root words\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "\n",
        "ps = PorterStemmer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EQ3o0M8icyE7"
      },
      "outputs": [],
      "source": [
        "def stem(text):\n",
        "  y = []\n",
        "  for txt in text.split():\n",
        "    y.append(ps.stem(text))\n",
        "  return \" \".join(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BYaylzuqcyIV"
      },
      "outputs": [],
      "source": [
        "new_df[\"tags\"] = new_df[\"tags\"].apply(stem)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTWXB6XhnRzQ"
      },
      "source": [
        "**Using CountVectorizer to convert strings into vectors**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MOB-Lj31iGiL"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Using CountVectorizer to make a matrix of count of different words\n",
        "\n",
        "# max_features determines the maximum number of words a vector can have\n",
        "# stop_words tells the object to ignore normal english words like and, to, be, ...\n",
        "\n",
        "vectorizer = CountVectorizer(max_features = 5000, stop_words = \"english\")\n",
        "\n",
        "count_matrix = vectorizer.fit_transform(new_df[\"tags\"]).toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sgPWMBBkiLEi"
      },
      "outputs": [],
      "source": [
        "vectorizer.get_feature_names()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gMMtc9OncjT"
      },
      "source": [
        "**Calculating Cosine Similarity**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23SKyYIWGJWK"
      },
      "outputs": [],
      "source": [
        "# As the dimension of data is higher, euclidean distance can't be used to get proper result. Thats why we use angular distance.\n",
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Calculating Cosine Similarity\n",
        "cosine_sim = cosine_similarity(count_matrix)\n",
        "\n",
        "cosine_sim.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfspouEmniLL"
      },
      "source": [
        "**Recommending Movies**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SnOxOOgBkesT"
      },
      "outputs": [],
      "source": [
        "# Helper Functions\n",
        "\n",
        "def get_title_from_index(index):\n",
        "    return new_df.loc[index, \"title\"]\n",
        "\n",
        "def get_index_from_title(title):\n",
        "    return new_df.loc[df.title == title].index[0]\n",
        "\n",
        "def recommend(movie):\n",
        "  # Getting movie index from dataframe\n",
        "  movie_index = get_index_from_title(movie)\n",
        "  # finding the vector with similarity values for that movie w.r.t all other movies\n",
        "  distances = cosine_sim[movie_index]\n",
        "  # sorting the similarity values in descending order along with their indices and taking top 5 movies\n",
        "  movies_list = sorted(list(enumerate(distances)), reverse = True, key = lambda x : x[1])[1:6]\n",
        "  # Traversing the movies list\n",
        "  for movie_name in movies_list:\n",
        "    # Using the get_title_from_index function to get movie_name from the index in dataframe\n",
        "    print(get_title_from_index(movie_name[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "60JNfnL2GJZl"
      },
      "outputs": [],
      "source": [
        "recommend(\"Avatar\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W32LYcSsryLZ"
      },
      "outputs": [],
      "source": [
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TRIqRhf1ryNe"
      },
      "outputs": [],
      "source": [
        "pickle.dump(new_df.to_dict(), open(\"movie_dict.pkl\", \"wb\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wP6l2we0ryQK"
      },
      "outputs": [],
      "source": [
        "pickle.dump(cosine_sim, open(\"cosine_similarity.pkl\", \"wb\"))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}