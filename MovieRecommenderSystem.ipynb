{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VidyasriAsarla/Mini_project/blob/main/MovieRecommenderSystem.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VCihp32AFjXI"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pmnLNvw6FpOO"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "# uploaded = files.upload()\n",
        "df1 = pd.read_csv(\"tmdb_5000_movies.csv\")\n",
        "df2 = pd.read_csv(\"tmdb_5000_credits.csv\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-HSEDpxrWwUf"
      },
      "source": [
        "**Data Preprocessing Starts**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EVMwlfzCMF0y"
      },
      "outputs": [],
      "source": [
        "df1.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QF6yXswyMKgP"
      },
      "outputs": [],
      "source": [
        "df2.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YnMCOLnJFpQ3"
      },
      "outputs": [],
      "source": [
        "df = df1.merge(df2, on = \"title\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kV3qdWJKMZF-"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fjUpX4XGMZHz"
      },
      "outputs": [],
      "source": [
        "df[\"original_language\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U4Uovk0QMZLQ"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LBwavqL2FpUS"
      },
      "outputs": [],
      "source": [
        "# Selecting features\n",
        "features = [\"movie_id\", \"title\", \"overview\", \"genres\", \"keywords\", \"cast\", \"crew\"]\n",
        "\n",
        "df = df[features]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5n2ucEmqPhKK"
      },
      "outputs": [],
      "source": [
        "# Removing rows with nan values\n",
        "df.dropna(inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pgJCEZ0uP62W"
      },
      "outputs": [],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_-RNNFhcPo4p"
      },
      "outputs": [],
      "source": [
        "# Checking for duplicate rows\n",
        "df.duplicated().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "895BqusPQMH9"
      },
      "outputs": [],
      "source": [
        "df.iloc[0].genres"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iE45-SHkQZDj"
      },
      "outputs": [],
      "source": [
        "import ast\n",
        "def convert(obj):\n",
        "  _list = []\n",
        "  # ast.literal_eval converts string into dictionary or object\n",
        "  for val in ast.literal_eval(obj):\n",
        "    _list.append(val[\"name\"])\n",
        "  return _list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iGnkw8xkQ1fI"
      },
      "outputs": [],
      "source": [
        "# Making a list of only genres and not including unwanted data\n",
        "df[\"genres\"] = df[\"genres\"].apply(convert)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vt33RNP2Q1il"
      },
      "outputs": [],
      "source": [
        "# Making a list of only keywords and not including unwanted data\n",
        "df[\"keywords\"] = df[\"keywords\"].apply(convert)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tNCWvSOdRluC"
      },
      "outputs": [],
      "source": [
        "df[\"cast\"][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "thRWxf8BRlwA"
      },
      "outputs": [],
      "source": [
        "# We want only most important actors in the cast\n",
        "def get_top_actors(obj):\n",
        "  _list = []\n",
        "  count = 0\n",
        "  for val in ast.literal_eval(obj):\n",
        "    if count == 3:\n",
        "      break\n",
        "    _list.append(val[\"name\"])\n",
        "    count += 1\n",
        "  return _list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hs2DBShKRlzb"
      },
      "outputs": [],
      "source": [
        "# Making a list of only top 3 actors in the movie\n",
        "df[\"cast\"] = df[\"cast\"].apply(get_top_actors)\n",
        "df[\"cast\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GqgBjRgCSDny"
      },
      "outputs": [],
      "source": [
        "df[\"crew\"][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f0W9Q9oqSDp_"
      },
      "outputs": [],
      "source": [
        "# We want only director from the crew\n",
        "def get_director(obj):\n",
        "  _list = []\n",
        "  count = 0\n",
        "  for val in ast.literal_eval(obj):\n",
        "    if val[\"job\"] == \"Director\":\n",
        "      _list.append(val[\"name\"])\n",
        "      break\n",
        "  return _list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_mLymfOKSDtf"
      },
      "outputs": [],
      "source": [
        "# Making a list of directors only from the crew\n",
        "df[\"directors\"] = df[\"crew\"].apply(get_director)\n",
        "df[\"directors\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "63mpgB-aTiv7"
      },
      "outputs": [],
      "source": [
        "df[\"overview\"][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JwG3FRFITizp"
      },
      "outputs": [],
      "source": [
        "# Converting string into list of overview\n",
        "df[\"overview\"] = df[\"overview\"].apply(lambda x: x.split())\n",
        "df[\"overview\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YrvxjpG0Ti3M"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-jQq4v5HUOY_"
      },
      "outputs": [],
      "source": [
        "# Replacing spaces with empty string in all columns   (This helps model to differentiate between 2 different strings that have same first name)\n",
        "df[\"genres\"] = df[\"genres\"].apply(lambda x : [i.replace(\" \", \"\") for i in x])\n",
        "df[\"keywords\"] = df[\"keywords\"].apply(lambda x : [i.replace(\" \", \"\") for i in x])\n",
        "df[\"cast\"] = df[\"cast\"].apply(lambda x : [i.replace(\" \", \"\") for i in x])\n",
        "df[\"directors\"] = df[\"directors\"].apply(lambda x : [i.replace(\" \", \"\") for i in x])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VJ94OXLjUOat"
      },
      "outputs": [],
      "source": [
        "# Making a new column tags that stores all the data of all the 4 columns\n",
        "df[\"tags\"] = df[\"overview\"] + df[\"keywords\"] + df[\"cast\"] + df[\"directors\"]\n",
        "df[\"tags\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pCEgNGM6UOch"
      },
      "outputs": [],
      "source": [
        "# Creating a new dataframe of just 3 columns after doing so  much preprocessing\n",
        "new_df = df[[\"movie_id\", \"title\", \"tags\"]]\n",
        "new_df[\"tags\"][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0VzKMhC-UOep"
      },
      "outputs": [],
      "source": [
        "# Converting list into string with spaces\n",
        "new_df[\"tags\"] = new_df[\"tags\"].apply(lambda x : \" \".join(x))\n",
        "new_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nEiICb0HUOh6"
      },
      "outputs": [],
      "source": [
        "# Making all the letters in the string to lowercase\n",
        "new_df[\"tags\"] = new_df[\"tags\"].apply(lambda x : x.lower())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smdJ8sWKW-Up"
      },
      "source": [
        "**Using Stemming technique to convert normal words into root words**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yOa4rZOib9C9"
      },
      "outputs": [],
      "source": [
        "# As we can see similar words are considered as different words in the vectorizer, we will use stemming to remove this ambiguity\n",
        "# stemming converts all the words to its root words\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "\n",
        "ps = PorterStemmer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EQ3o0M8icyE7"
      },
      "outputs": [],
      "source": [
        "def stem(text):\n",
        "  y = []\n",
        "  for txt in text.split():\n",
        "    y.append(ps.stem(text))\n",
        "  return \" \".join(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BYaylzuqcyIV"
      },
      "outputs": [],
      "source": [
        "new_df[\"tags\"] = new_df[\"tags\"].apply(stem)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTWXB6XhnRzQ"
      },
      "source": [
        "**Using CountVectorizer to convert strings into vectors**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MOB-Lj31iGiL"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Using CountVectorizer to make a matrix of count of different words\n",
        "\n",
        "# max_features determines the maximum number of words a vector can have\n",
        "# stop_words tells the object to ignore normal english words like and, to, be, ...\n",
        "\n",
        "vectorizer = CountVectorizer(max_features = 5000, stop_words = \"english\")\n",
        "\n",
        "count_matrix = vectorizer.fit_transform(new_df[\"tags\"]).toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sgPWMBBkiLEi"
      },
      "outputs": [],
      "source": [
        "vectorizer.get_feature_names()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gMMtc9OncjT"
      },
      "source": [
        "**Calculating Cosine Similarity**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23SKyYIWGJWK"
      },
      "outputs": [],
      "source": [
        "# As the dimension of data is higher, euclidean distance can't be used to get proper result. Thats why we use angular distance.\n",
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Calculating Cosine Similarity\n",
        "cosine_sim = cosine_similarity(count_matrix)\n",
        "\n",
        "cosine_sim.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfspouEmniLL"
      },
      "source": [
        "**Recommending Movies**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SnOxOOgBkesT"
      },
      "outputs": [],
      "source": [
        "# Helper Functions\n",
        "\n",
        "def get_title_from_index(index):\n",
        "    return new_df.loc[index, \"title\"]\n",
        "\n",
        "def get_index_from_title(title):\n",
        "    return new_df.loc[df.title == title].index[0]\n",
        "\n",
        "def recommend(movie):\n",
        "  # Getting movie index from dataframe\n",
        "  movie_index = get_index_from_title(movie)\n",
        "  # finding the vector with similarity values for that movie w.r.t all other movies\n",
        "  distances = cosine_sim[movie_index]\n",
        "  # sorting the similarity values in descending order along with their indices and taking top 5 movies\n",
        "  movies_list = sorted(list(enumerate(distances)), reverse = True, key = lambda x : x[1])[1:6]\n",
        "  # Traversing the movies list\n",
        "  for movie_name in movies_list:\n",
        "    # Using the get_title_from_index function to get movie_name from the index in dataframe\n",
        "    print(get_title_from_index(movie_name[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "60JNfnL2GJZl"
      },
      "outputs": [],
      "source": [
        "recommend(\"Avatar\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W32LYcSsryLZ"
      },
      "outputs": [],
      "source": [
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TRIqRhf1ryNe"
      },
      "outputs": [],
      "source": [
        "pickle.dump(new_df.to_dict(), open(\"movie_dict.pkl\", \"wb\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wP6l2we0ryQK"
      },
      "outputs": [],
      "source": [
        "pickle.dump(cosine_sim, open(\"cosine_similarity.pkl\", \"wb\"))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}